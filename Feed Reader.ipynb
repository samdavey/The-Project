{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing an RSS feed\n",
    "This is a work in progress technical POC with the objective of:\n",
    "1. Taking an RSS feed URL\n",
    "2. Reading the items on the feed\n",
    "3. Linking through to the source articles\n",
    "4. Creating a datastructure to hold the atricle and metadata\n",
    "\n",
    "This is intended to be passed to an NL parser that interprets it, a handler that stores the article datastructure and interpretation and a controller that decides whether action should be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set testing to 1 if you want to run absolutely everything\n",
    "testing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Before running, use 'pip install feedparser'\n",
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the feedparser to get an RSS feed. This is from my personal Google News\n",
    "feed = 'http://news.google.com/news?cf=all&hl=en&pz=1&ned=au&q=lucapa+diamond+company+kimberlite&output=rss'\n",
    "parser = feedparser.parse(feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing to understand the feed data structure. Don't need to run.\n",
    "# Check the feed metadata\n",
    "if testing = 1:\n",
    "    print(parser['feed'])\n",
    "    print('\\n')\n",
    "    print(parser['feed']['title'])\n",
    "    print('\\n')\n",
    "    print(parser['feed']['link'])\n",
    "    print('\\n')\n",
    "    print(parser['feed']['updated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Testing to understand the feed data structure. Don't need to run.\n",
    "# How many articles do we have?\n",
    "if testing = 1:\n",
    "    print(len(parser['entries']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Link:\n",
      "http://news.google.com/news/url?sa=t&fd=R&ct2=au&usg=AFQjCNE_p9Dej1a3iSOVhCNsqDaIo9-YdQ&clid=c3a7d30bb8a4878e06b80cf16b898331&cid=52779048508106&ei=YKbGVsi4D4GV4ALJ3r9o&url=http://www.forbes.com/sites/trevornace/2016/02/17/largest-diamond-found-angola-flawless-404-carats/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing to understand the feed data structure. Don't need to run.\n",
    "# What's in entry 1?\n",
    "#print(parser['entries'][0])\n",
    "#if testing = 1:\n",
    "#print('\\nTitle:\\n' + parser['entries'][0]['title_detail']['value'] + '\\n')\n",
    "#print('\\nPublished:\\n' + parser['entries'][0]['published'] + '\\n')\n",
    "print('\\nLink:\\n' + parser['entries'][0]['link'] + '\\n')\n",
    "#print('\\nSummary:\\n' + parser['entries'][0]['summary_detail']['value'] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The datastructure we want is probably the following:\n",
    "### Article\n",
    "- **id** : a md5 hash of the article URL; only the real bits not the click-through crap\n",
    "- **metadata_feed_name** : name of the RSS feed or search criteria that returned this article\n",
    "- **metadata_feed_link** : URL for the feed that teh article was sourced from\n",
    "- **metadata_feed_accessed** : timestamp when the article was obtained (the first time, duplicates are dropped)\n",
    "- **article_title** : title\n",
    "- **article_published** : timestamp when the article was first published\n",
    "- **article_publisher** : the news source\n",
    "- **article_link** : link to the article (minus the click-through crap)\n",
    "- **article_content** : the text of the article (scrape the HTML and keep only the body content)\n",
    "\n",
    "We then do natural language processing on the Article and produce a new table of article_ids and tuples that represent the themes of the article. E.g. (noun, verb, preposition etc), ('BHP', 'dam', 'collapse'), ('Australian company Lucapa', 'finds', 'huge diamond', 'Angola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Article Start ---\n",
      "\n",
      "article_title :  A tiny Australian miner just found this huge diamond - Business Insider Australia\n",
      "article_link :  http://www.businessinsider.com.au/a-tiny-australian-miner-just-found-this-huge-diamond-in-africa-2016-2\n",
      "metadata_feed_name :  lucapa diamond company kimberlite - Google News\n",
      "metadata_feed_accessed :  Thu, 18 Feb 2016 13:25:26 GMT\n",
      "article_published :  Mon, 15 Feb 2016 01:24:27 GMT\n",
      "metadata_feed_link :  http://news.google.com/news?hl=en&pz=1&ned=au&q=lucapa+diamond+company+kimberlite\n",
      "id :  8af41cc74cd5330faa7d35db6f890694\n",
      "article_publisher :  Business Insider Australia\n",
      "--- Article End ---\n",
      "\n",
      "--- Article Start ---\n",
      "\n",
      "article_title :  Largest Diamond Ever Found In Angola: Near Flawless & 404-Carats - Forbes\n",
      "article_link :  http://www.forbes.com/sites/trevornace/2016/02/17/largest-diamond-found-angola-flawless-404-carats/\n",
      "metadata_feed_name :  lucapa diamond company kimberlite - Google News\n",
      "metadata_feed_accessed :  Thu, 18 Feb 2016 13:25:26 GMT\n",
      "article_published :  Thu, 18 Feb 2016 01:34:34 GMT\n",
      "metadata_feed_link :  http://news.google.com/news?hl=en&pz=1&ned=au&q=lucapa+diamond+company+kimberlite\n",
      "id :  5ba49d54220066e46fd047fc30f6c27f\n",
      "article_publisher :  Forbes\n",
      "--- Article End ---\n",
      "\n",
      "--- Article Start ---\n",
      "\n",
      "article_title :  Lucapa's trading halt raises big expectations - The Australian\n",
      "article_link :  http://news.google.com/news/url?sa=t&fd=R&ct2=au&usg=AFQjCNHLDJwiVb_l8oM2xWxKPr0yX63lBQ&clid=c3a7d30bb8a4878e06b80cf16b898331&cid=52779043855399&ei=RsbFVpiMI4GV4AKU-bPgCw&url=http://www.theaustralian.com.au/business/companies/lucapas-trading-halt-raises-big-expectations/news-story/63e01267d02857cffc2cb60c4ca4407d\n",
      "metadata_feed_name :  lucapa diamond company kimberlite - Google News\n",
      "metadata_feed_accessed :  Thu, 18 Feb 2016 13:25:26 GMT\n",
      "article_published :  Sun, 07 Feb 2016 13:04:03 GMT\n",
      "metadata_feed_link :  http://news.google.com/news?hl=en&pz=1&ned=au&q=lucapa+diamond+company+kimberlite\n",
      "id :  965576df70cf96ab387a51ceec14e0db\n",
      "article_publisher :  \n",
      "--- Article End ---\n",
      "\n",
      "--- Article Start ---\n",
      "\n",
      "article_title :  Morning Headlines - Business News\n",
      "article_link :  https://www.businessnews.com.au/article/Morning-Headlines-656\n",
      "metadata_feed_name :  lucapa diamond company kimberlite - Google News\n",
      "metadata_feed_accessed :  Thu, 18 Feb 2016 13:25:26 GMT\n",
      "article_published :  Mon, 15 Feb 2016 22:45:06 GMT\n",
      "metadata_feed_link :  http://news.google.com/news?hl=en&pz=1&ned=au&q=lucapa+diamond+company+kimberlite\n",
      "id :  97125b4be65918c1111012a0f960e8bc\n",
      "article_publisher :  Business News\n",
      "--- Article End ---\n",
      "\n",
      "--- Article Start ---\n",
      "\n",
      "article_title :  Lucapa Identifies Kimberlitic Signature at L259 Kimberlite - Investing News Network (press release) (registration) (blog)\n",
      "article_link :  http://investingnews.com/daily/resource-investing/gem-investing/diamond-investing/lucapa-identifies-kimberlitic-signature-at-l259-kimberlite/\n",
      "metadata_feed_name :  lucapa diamond company kimberlite - Google News\n",
      "metadata_feed_accessed :  Thu, 18 Feb 2016 13:25:26 GMT\n",
      "article_published :  Mon, 01 Feb 2016 19:26:41 GMT\n",
      "metadata_feed_link :  http://news.google.com/news?hl=en&pz=1&ned=au&q=lucapa+diamond+company+kimberlite\n",
      "id :  f1212042251f6fa345b2b3733a86fa51\n",
      "article_publisher :  Investing News Network\n",
      "--- Article End ---\n",
      "\n",
      "--- Article Start ---\n",
      "\n",
      "article_title :  Lucapa up on diamond find - The West Australian\n",
      "article_link :  https://au.news.yahoo.com/thewest/wa/a/30633931/lucapa-up-on-diamond-find/\n",
      "metadata_feed_name :  lucapa diamond company kimberlite - Google News\n",
      "metadata_feed_accessed :  Thu, 18 Feb 2016 13:25:26 GMT\n",
      "article_published :  Fri, 22 Jan 2016 01:22:59 GMT\n",
      "metadata_feed_link :  http://news.google.com/news?hl=en&pz=1&ned=au&q=lucapa+diamond+company+kimberlite\n",
      "id :  99ff758c8fe89b0f8fe83f6c340d499b\n",
      "article_publisher :  \n",
      "--- Article End ---\n",
      "\n",
      "--- Article Start ---\n",
      "\n",
      "article_title :  Lucapa Recovers 2 Large Alluvial Type II-a Specials from Lulo - IDEX Online\n",
      "article_link :  http://news.google.com/news/url?sa=t&fd=R&ct2=au&usg=AFQjCNGmY90-PNm2dt8sP2FXn9wV8ss5sg&clid=c3a7d30bb8a4878e06b80cf16b898331&ei=RsbFVpiMI4GV4AKU-bPgCw&url=http://www.idexonline.com/FullArticle?Id%3D41609\n",
      "metadata_feed_name :  lucapa diamond company kimberlite - Google News\n",
      "metadata_feed_accessed :  Thu, 18 Feb 2016 13:25:26 GMT\n",
      "article_published :  Thu, 04 Feb 2016 07:56:18 GMT\n",
      "metadata_feed_link :  http://news.google.com/news?hl=en&pz=1&ned=au&q=lucapa+diamond+company+kimberlite\n",
      "id :  612584744decf30d4e7da6078605ae3d\n",
      "article_publisher :  \n",
      "--- Article End ---\n",
      "\n",
      "--- Article Start ---\n",
      "\n",
      "article_title :  Lucapa Recovers Largest Diamond Ever from Lulo Mine in Angola - Rapaport\n",
      "article_link :  http://www.diamonds.net/News/NewsItem.aspx?ArticleID=54361&ArticleTitle=Lucapa+Recovers+Largest+Diamond+Ever+from+Lulo+Mine+in+Angola\n",
      "metadata_feed_name :  lucapa diamond company kimberlite - Google News\n",
      "metadata_feed_accessed :  Thu, 18 Feb 2016 13:25:26 GMT\n",
      "article_published :  Sun, 24 Jan 2016 13:54:30 GMT\n",
      "metadata_feed_link :  http://news.google.com/news?hl=en&pz=1&ned=au&q=lucapa+diamond+company+kimberlite\n",
      "id :  6c7c750060813ef7a10720fa0b84c83a\n",
      "article_publisher :  \n",
      "--- Article End ---\n",
      "\n",
      "--- Article Start ---\n",
      "\n",
      "article_title :  Lucapa Finds Confirmed Kimberlite at Angola Project - Rapaport\n",
      "article_link :  http://www.diamonds.net/News/NewsItem.aspx?ArticleID=53535&ArticleTitle=Lucapa+Finds+Confirmed+Kimberlite+at+Angola+Project\n",
      "metadata_feed_name :  lucapa diamond company kimberlite - Google News\n",
      "metadata_feed_accessed :  Thu, 18 Feb 2016 13:25:26 GMT\n",
      "article_published :  Wed, 07 Oct 2015 09:51:43 GMT\n",
      "metadata_feed_link :  http://news.google.com/news?hl=en&pz=1&ned=au&q=lucapa+diamond+company+kimberlite\n",
      "id :  f21395127fc16e361c81602928c4fb03\n",
      "article_publisher :  \n",
      "--- Article End ---\n",
      "\n",
      "--- Article Start ---\n",
      "\n",
      "article_title :  Lucapa closes in on gem source - The West Australian\n",
      "article_link :  https://au.news.yahoo.com/thewest/wa/a/29730849/lucapa-closes-in-on-gem-source/\n",
      "metadata_feed_name :  lucapa diamond company kimberlite - Google News\n",
      "metadata_feed_accessed :  Thu, 18 Feb 2016 13:25:26 GMT\n",
      "article_published :  Tue, 06 Oct 2015 01:20:19 GMT\n",
      "metadata_feed_link :  http://news.google.com/news?hl=en&pz=1&ned=au&q=lucapa+diamond+company+kimberlite\n",
      "id :  b8f190f75a7674df1ca226726026410a\n",
      "article_publisher :  \n",
      "--- Article End ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now save the summary of the whole list\n",
    "summary = []\n",
    "\n",
    "for item in parser['entries']:\n",
    "    \n",
    "    # Initiate the HTML parser for this article\n",
    "    article_html = requests.get(item.link).text\n",
    "    soup = BeautifulSoup(article_html, 'html.parser')\n",
    "    \n",
    "    # All decent articles should have Facebook OpenGraph tags that look like <meta property=\"og:type\" content=\"article\" />\n",
    "    # These have useful stuff to describe the article, including site_name and the clean URL\n",
    "    # If the Facebook OG tags are not present, try the Twitter ones, else leave the publisher blank, use the messy link.\n",
    "    publisher = ''\n",
    "       \n",
    "    # Check for a standard meta-publisher tag\n",
    "    publisher_search = soup.find('meta', attrs={'property': 'publisher', 'content': True})\n",
    "    if publisher_search:\n",
    "        publisher = publisher_search['content']\n",
    "    else:\n",
    "        # No meta-publisher, so look for a Facebook publisher tag\n",
    "        publisher_search = soup.find('meta', attrs={'property': 'og:site_name', 'content': True})\n",
    "        if publisher_search:\n",
    "            publisher = publisher_search['content']\n",
    "    \n",
    "    link = item.link\n",
    "    \n",
    "    # Check for a Facebook URL (og:url)\n",
    "    link_search = soup.find('meta', attrs={'property': 'og:url', 'content': True})\n",
    "    if link_search:\n",
    "        link = link_search['content']\n",
    "        \n",
    "    # That failed, so try for a Twitter one (twitter:url)\n",
    "    if link_search == None:\n",
    "        link_search = soup.find('meta', attrs={'property': 'twitter:url', 'content': True})\n",
    "        if link_search:\n",
    "            link = link_search['content']\n",
    "            \n",
    "    # That failed, so try for a 'link rel=\"canonical\"'\n",
    "    if link_search == None:\n",
    "        link_search = soup.find('link', attrs={'rel': 'canonical', 'href': True})\n",
    "        if link_search:\n",
    "            link = link_search['href']\n",
    "    # If we found a result (link_search != None), then we've updated 'link', else it still contains the messy link \n",
    "    \n",
    "    summary.append({'id': hashlib.md5(link.encode('utf-8')).hexdigest(),\n",
    "                    'metadata_feed_name': parser.feed.title, \n",
    "                    'metadata_feed_link': parser.feed.link,\n",
    "                    'metadata_feed_accessed': parser.feed.updated, \n",
    "                    'article_title': item.title, \n",
    "                    'article_published': item.published, \n",
    "                    'article_publisher': publisher,\n",
    "                    'article_link': link,\n",
    "                    'article_content': article_html\n",
    "                   })\n",
    "\n",
    "# Print it so we know it worked; remember that dictionaries are not ordered\n",
    "for items in summary:\n",
    "    print('--- Article Start ---')\n",
    "    for keys,values in items.items():\n",
    "        if keys != 'article_content':\n",
    "            print(keys, ':\\t', values)\n",
    "    print('--- Article End ---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bugs:\n",
    "- Strip crap out of RSS article links\n",
    "- Parse time stamps into useable formats\n",
    "- Parse the publisher out of the URL or maybe the site name?\n",
    "- Scraping the articles gets super confusing witht eh amount of shit tags. Maybe take everything from the start of the 1st 'h1' to the start of the next 'h1'. In between there should be the actual data and not the page comments and advertising crap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guidislink': False,\n",
       " 'id': 'tag:news.google.com,2005:cluster=http://venturebeat.com/2016/02/18/yahoos-flurry-unveils-redesign-launches-analytics-apps-and-apple-tv-sdk/',\n",
       " 'link': 'http://news.google.com/news/url?sa=t&fd=R&ct2=au&usg=AFQjCNHbjeV4YOkJzxGmKtHpCEfFXVu3bg&clid=c3a7d30bb8a4878e06b80cf16b898331&cid=52779049021818&ei=RqzGVsCrMIyh4ALto7GYDA&url=http://venturebeat.com/2016/02/18/yahoos-flurry-unveils-redesign-launches-analytics-apps-and-apple-tv-sdk/',\n",
       " 'links': [{'href': 'http://news.google.com/news/url?sa=t&fd=R&ct2=au&usg=AFQjCNHbjeV4YOkJzxGmKtHpCEfFXVu3bg&clid=c3a7d30bb8a4878e06b80cf16b898331&cid=52779049021818&ei=RqzGVsCrMIyh4ALto7GYDA&url=http://venturebeat.com/2016/02/18/yahoos-flurry-unveils-redesign-launches-analytics-apps-and-apple-tv-sdk/',\n",
       "   'rel': 'alternate',\n",
       "   'type': 'text/html'}],\n",
       " 'published': 'Fri, 19 Feb 2016 01:47:31 GMT',\n",
       " 'published_parsed': time.struct_time(tm_year=2016, tm_mon=2, tm_mday=19, tm_hour=1, tm_min=47, tm_sec=31, tm_wday=4, tm_yday=50, tm_isdst=0),\n",
       " 'summary': '<table border=\"0\" cellpadding=\"2\" cellspacing=\"7\" style=\"vertical-align:top;\"><tr><td width=\"80\" align=\"center\" valign=\"top\"><font style=\"font-size:85%;font-family:arial,sans-serif\"><a href=\"http://news.google.com/news/url?sa=t&amp;fd=R&amp;ct2=au&amp;usg=AFQjCNHbjeV4YOkJzxGmKtHpCEfFXVu3bg&amp;clid=c3a7d30bb8a4878e06b80cf16b898331&amp;cid=52779049021818&amp;ei=RqzGVsCrMIyh4ALto7GYDA&amp;url=http://venturebeat.com/2016/02/18/yahoos-flurry-unveils-redesign-launches-analytics-apps-and-apple-tv-sdk/\"><img src=\"//t3.gstatic.com/images?q=tbn:ANd9GcTR_YZwewqR8Nrg8wcGWudMlTxpuaupTntqt-g_f8kHk3mP01KqpXqgwqdtjsNh_ciKbgzMQbw\" alt=\"\" border=\"1\" width=\"80\" height=\"80\"><br><font size=\"-2\">VentureBeat</font></a></font></td><td valign=\"top\" class=\"j\"><font style=\"font-size:85%;font-family:arial,sans-serif\"><br><div style=\"padding-top:0.8em;\"><img alt=\"\" height=\"1\" width=\"1\"></div><div class=\"lh\"><a href=\"http://news.google.com/news/url?sa=t&amp;fd=R&amp;ct2=au&amp;usg=AFQjCNHbjeV4YOkJzxGmKtHpCEfFXVu3bg&amp;clid=c3a7d30bb8a4878e06b80cf16b898331&amp;cid=52779049021818&amp;ei=RqzGVsCrMIyh4ALto7GYDA&amp;url=http://venturebeat.com/2016/02/18/yahoos-flurry-unveils-redesign-launches-analytics-apps-and-apple-tv-sdk/\"><b>Yahoo&#39;s Flurry unveils redesign, launches <b>analytics</b> apps and Apple TV SDK</b></a><br><font size=\"-1\"><b><font color=\"#6f6f6f\">VentureBeat</font></b></font><br><font size=\"-1\">SAN FRANCISCO — Yahoo has released a few updates for Flurry, the data and app <b>analytics</b> service it acquired in 2014. The company not only announced today the redesign of its metrics portal, but also the release of a tvOS developer kit, and new apps <b>...</b></font><br><font size=\"-1\" class=\"p\"></font><br><font class=\"p\" size=\"-1\"><a class=\"p\" href=\"http://news.google.com/news/more?ncl=dvSJHQCbvgYhdhM&amp;authuser=0&amp;ned=au\"><nobr><b>and more&nbsp;&raquo;</b></nobr></a></font></div></font></td></tr></table>',\n",
       " 'summary_detail': {'base': 'https://news.google.com/news?cf=all&hl=en&pz=1&ned=au&q=analytics&output=rss',\n",
       "  'language': None,\n",
       "  'type': 'text/html',\n",
       "  'value': '<table border=\"0\" cellpadding=\"2\" cellspacing=\"7\" style=\"vertical-align:top;\"><tr><td width=\"80\" align=\"center\" valign=\"top\"><font style=\"font-size:85%;font-family:arial,sans-serif\"><a href=\"http://news.google.com/news/url?sa=t&amp;fd=R&amp;ct2=au&amp;usg=AFQjCNHbjeV4YOkJzxGmKtHpCEfFXVu3bg&amp;clid=c3a7d30bb8a4878e06b80cf16b898331&amp;cid=52779049021818&amp;ei=RqzGVsCrMIyh4ALto7GYDA&amp;url=http://venturebeat.com/2016/02/18/yahoos-flurry-unveils-redesign-launches-analytics-apps-and-apple-tv-sdk/\"><img src=\"//t3.gstatic.com/images?q=tbn:ANd9GcTR_YZwewqR8Nrg8wcGWudMlTxpuaupTntqt-g_f8kHk3mP01KqpXqgwqdtjsNh_ciKbgzMQbw\" alt=\"\" border=\"1\" width=\"80\" height=\"80\"><br><font size=\"-2\">VentureBeat</font></a></font></td><td valign=\"top\" class=\"j\"><font style=\"font-size:85%;font-family:arial,sans-serif\"><br><div style=\"padding-top:0.8em;\"><img alt=\"\" height=\"1\" width=\"1\"></div><div class=\"lh\"><a href=\"http://news.google.com/news/url?sa=t&amp;fd=R&amp;ct2=au&amp;usg=AFQjCNHbjeV4YOkJzxGmKtHpCEfFXVu3bg&amp;clid=c3a7d30bb8a4878e06b80cf16b898331&amp;cid=52779049021818&amp;ei=RqzGVsCrMIyh4ALto7GYDA&amp;url=http://venturebeat.com/2016/02/18/yahoos-flurry-unveils-redesign-launches-analytics-apps-and-apple-tv-sdk/\"><b>Yahoo&#39;s Flurry unveils redesign, launches <b>analytics</b> apps and Apple TV SDK</b></a><br><font size=\"-1\"><b><font color=\"#6f6f6f\">VentureBeat</font></b></font><br><font size=\"-1\">SAN FRANCISCO — Yahoo has released a few updates for Flurry, the data and app <b>analytics</b> service it acquired in 2014. The company not only announced today the redesign of its metrics portal, but also the release of a tvOS developer kit, and new apps <b>...</b></font><br><font size=\"-1\" class=\"p\"></font><br><font class=\"p\" size=\"-1\"><a class=\"p\" href=\"http://news.google.com/news/more?ncl=dvSJHQCbvgYhdhM&amp;authuser=0&amp;ned=au\"><nobr><b>and more&nbsp;&raquo;</b></nobr></a></font></div></font></td></tr></table>'},\n",
       " 'title': \"Yahoo's Flurry unveils redesign, launches analytics apps and Apple TV SDK - VentureBeat\",\n",
       " 'title_detail': {'base': 'https://news.google.com/news?cf=all&hl=en&pz=1&ned=au&q=analytics&output=rss',\n",
       "  'language': None,\n",
       "  'type': 'text/plain',\n",
       "  'value': \"Yahoo's Flurry unveils redesign, launches analytics apps and Apple TV SDK - VentureBeat\"}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed = 'http://news.google.com/news?cf=all&hl=en&pz=1&ned=au&q=analytics&output=rss'\n",
    "parser = feedparser.parse(feed)\n",
    "parser['entries'][0]\n",
    "#for keys,values in parser['entries'][0]:\n",
    "#    print(keys, ':\\t', values, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
